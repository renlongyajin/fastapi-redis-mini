# 详细开发手册

面向对象：准备面试、需要一套最小但可运行的 FastAPI + Redis + 异步任务演示项目的开发者。

---

## 目录
1. 快速概览
2. 环境与依赖
3. 目录结构约定
4. 核心模块实现步骤
5. 配置项说明
6. API 规格与交互流程
7. Worker 与异步执行
8. Redis 数据模型
9. Profiling 与性能验证
10. Docker 化与部署示例
11. 验收与测试清单
12. 常见问题

---

## 1. 快速概览
- **目标**：在 2~3 天内完成一个端到端 Demo，证明你理解框架、中间件、异步任务、性能与部署。
- **技术栈**：Python 3.11、FastAPI、Uvicorn/Gunicorn、Redis、asyncio、cProfile、Docker Compose。
- **核心流程**：`客户端请求 → FastAPI 校验与入列 → Redis Stream 排队 → Worker 异步执行 → Redis 缓存结果 → 客户端查询`。

## 2. 环境与依赖
- Python ≥ 3.11（建议使用 `pyenv` 或 `conda`）
- Redis ≥ 6.2（本地或 Docker 容器）
- Poetry 或 pip + venv
- Docker / Docker Compose（可选但建议，方便演示部署）

### 基础命令
```bash
python -m venv .venv && source .venv/bin/activate
pip install --upgrade pip
pip install fastapi uvicorn[standard] redis pydantic[dotenv] tenacity python-dotenv
pip install aiohttp (如需调用外部服务)
pip install pytest httpx (用于测试)
```

## 3. 目录结构约定
```
fastapi-redis-mini/
├── app/
│   ├── main.py           # FastAPI 入口
│   ├── schemas.py        # Pydantic 模型
│   ├── dependencies.py   # Redis / 配置注入
│   └── services/
│       ├── task_service.py
│       └── cache_service.py
├── worker/
│   ├── runner.py         # Worker 主循环
│   └── job_handler.py
├── infra/
│   ├── redis_client.py   # 统一连接与序列化
│   └── settings.py       # 读取 .env 配置
├── tools/
│   ├── profile.py        # cProfile/py-spy 包装
│   └── load_test.py      # 简单压测脚本
├── tests/
│   ├── test_end_to_end.py
│   └── test_cache.py
├── docker-compose.yml
├── Dockerfile.api
├── Dockerfile.worker
├── .env.example
└── README.md
```

## 4. 核心模块实现步骤
1. **配置层 (`infra/settings.py`)**：使用 Pydantic `BaseSettings` 读取 `REDIS_URL`、`CACHE_TTL`、`QUEUE_KEY`、`MAX_CONCURRENCY`。
2. **Redis 客户端 (`infra/redis_client.py`)**：封装 `redis.asyncio.Redis` 单例，提供 `get_json/set_json/xadd/xreadgroup` 辅助函数。
3. **Schemas**：
   - `TaskRequest`（用户输入）
   - `TaskResponse`（返回 `task_id` + 状态）
   - `TaskStatus` Enum
4. **Service 层**：
   - `task_service.submit_task()`：生成 ID → 写 Hash → 推送队列 → 返回基础响应
   - `task_service.get_task()`：读取 Hash，拼装状态与结果
   - `cache_service.get_or_set()`：构建请求签名（哈希），命中则直接返回
5. **FastAPI 路由**：
   - `POST /tasks`：先查缓存 → 不命中则创建任务 → 返回 `task_id`
   - `GET /tasks/{id}`：返回状态；若 `DONE` 则附带结果
6. **Worker**：
   - 初始化 Redis 连接，加入消费组
   - 死循环阻塞读取队列，使用 `asyncio.create_task` 控制并发
   - 执行 `job_handler.handle_task(payload)`，内部 `await asyncio.sleep()` 模拟耗时
   - 成功后写 Hash + 缓存；失败时写 `FAILED` 与错误信息

## 5. 配置项说明
| 变量 | 默认值 | 说明 |
| --- | --- | --- |
| `REDIS_URL` | `redis://redis:6379/0` | 可换成本地 `localhost` |
| `QUEUE_KEY` | `task_stream` | Redis Stream/List 名称 |
| `CACHE_TTL` | `600` 秒 | 缓存命中后刷新 TTL |
| `MAX_CONCURRENCY` | `5` | Worker 内部最多并发任务数 |
| `RESULT_EXPIRY` | `86400` | `task:{id}` Hash 的保留时间 |

## 6. API 规格与交互流程
### 6.1 OpenAPI 摘要
- `POST /tasks`
  - 请求体：`{ "prompt": str, "params": {...} }`
  - 响应：`{ "task_id": str, "status": "PENDING", "cached": bool }`
- `GET /tasks/{task_id}`
  - 响应：`{ "task_id": str, "status": "RUNNING|DONE|FAILED", "result": Optional[Any], "error": Optional[str] }`

### 6.2 状态机
`PENDING → RUNNING → DONE` 或 `FAILED`，状态变化只发生在 Worker。

### 6.3 请求签名
```
signature = sha256(json.dumps(request_body, sort_keys=True)).hexdigest()
cache_key = f"cache:{signature}"
```

## 7. Worker 与异步执行
- 使用 `asyncio.Semaphore(MAX_CONCURRENCY)` 控制并发，避免 Redis 消费过快。
- 任务处理伪代码：
```python
async def handle_task(task_id, payload):
    await redis.hset(f"task:{task_id}", mapping={"status": "RUNNING"})
    await asyncio.sleep(payload["duration"], result=...)  # 模拟耗时
    await redis.hset(f"task:{task_id}", mapping={"status": "DONE", "result": json.dumps(result)})
```
- 失败时捕获异常，写入 `error` 字段并标记 `FAILED`。

## 8. Redis 数据模型
| Key | 类型 | 示例内容 |
| --- | --- | --- |
| `task:{id}` | Hash | `{status: RUNNING, result: {...}, error: ""}` |
| `cache:{signature}` | String | 序列化的结果，设置 `CACHE_TTL` |
| `task_stream` | Stream/List | `{"task_id": "..."}` |

> 生产可将 Stream 替换成 Kafka，但接口不变。

## 9. Profiling 与性能验证
- `tools/profile.py` 提供包装：
```bash
python tools/profile.py --module worker.runner --call main --output profile-worker.prof
snakeviz profile-worker.prof
```
- 也可使用 `py-spy top --pid <worker_pid>` 观察运行态热点。
- 负载测试脚本 `tools/load_test.py` 使用 `httpx.AsyncClient` 并发提交 100~500 个请求，计算平均等待时间。

## 10. Docker 化与部署示例
- `Dockerfile.api`：基于 `python:3.11-slim`，安装依赖，入口 `gunicorn -k uvicorn.workers.UvicornWorker -w 4 app.main:app`。
- `Dockerfile.worker`：同基镜像，但入口 `python worker/runner.py`。
- `docker-compose.yml`：
  - `api` 服务依赖 `redis`
  - `worker` 服务依赖 `redis`
  - `redis` 使用官方镜像，暴露 6379
- 启动命令：`docker compose up --build`。
- 生产口径：在 compose 基础上加 Nginx/负载均衡，或迁移到 K8s Deployment + Stateful Redis。

## 11. 验收与测试清单
1. 本地启动 Redis，运行 `uvicorn app.main:app --reload`、`python worker/runner.py`，提交任务成功。
2. 同一请求第二次提交命中缓存，响应 `cached=true`。
3. Worker 异常时任务状态变为 `FAILED` 且附带错误信息。
4. `pytest` 通过：
   - `tests/test_end_to_end.py`：完整流程
   - `tests/test_cache.py`：缓存 TTL 行为
5. `tools/profile.py` 生成报告并能用 snakeviz 打开。
6. `docker compose up` 后 API 可在 `http://localhost:8000/docs` 访问。

## 12. 常见问题
- **为什么不用 Celery/Kafka？** 因为目标是最小可运行示例；Redis Stream 足以表达排队与消费。面试时强调“可以平滑迁移到 Kafka”。
- **如何扩展 Worker？** 直接 scale Worker 容器或进程，确保每个 Worker 在自己的消费组内使用不同的 `consumer_name` 即可。
- **如何处理任务超时？** 在 Worker 中使用 `asyncio.wait_for` 包裹核心逻辑，并在超时时标记 `FAILED`。
- **如何兼容 Flask？** 如果被问到，可说明 FastAPI 的 ASGI + Pydantic 优势；Flask 更适合轻量脚本，但示例项目聚焦高并发场景。

---

> 只要严格按本手册执行，就能在极短时间内构建一个覆盖“框架 + 中间件 + 异步 + 部署 + 性能”全链路的教学级项目，并具备面试可讲述的材料。
