# 项目总体分析

## 1. 项目定位
- **项目名称**：FastAPI-Redis 异步任务最小实践（代号 `fastapi-redis-mini`）
- **核心命题**：围绕“AI 任务请求→排队→执行→缓存查询”这一真实场景，快速补齐框架、中间件、部署与性能思维
- **成果形式**：一个可运行的示例仓库（API + Worker + Redis + Docker Compose），配套 Profiling 示例和面试说辞

## 2. 解决的真实问题（Premise Check）
1. **Is this a real problem?** 是。现状缺乏系统工程经验，难以回答高阶面试；该项目直接覆盖常见后端题材。
2. **Is there a simpler way?** 有。选用 FastAPI + Redis 一站式完成缓存与队列，砍掉多余依赖。
3. **What does this break?** 无。架构遵循社区主流实践，兼容常规部署方式，不会破坏既有认知。

## 3. 核心组件与职责
- **FastAPI 服务 (`app/main.py`)**：提供 `POST /tasks`、`GET /tasks/{id}`，接入 Pydantic 校验与自动 OpenAPI；只做 IO、状态读取，不混入业务细节。
- **Redis 中间件**：
  - Hash：保存任务状态与结果，键为 `task:{id}`
  - Stream/List：充当简化版 Kafka 队列，主题 `task_stream`
  - KV：作为结果缓存，键 `cache:{request_signature}`，附带 TTL
- **Worker (`worker/runner.py`)**：订阅 Redis Stream，异步执行任务（`asyncio.sleep` 模拟推理），回写状态、刷新缓存。
- **Profiling 工具 (`tools/profile.py`)**：封装 cProfile/py-spy 的调用，输出热点函数。
- **Docker 化部署**：`docker-compose` 管理 3 个容器（API、Worker、Redis），演示最小生产拓扑。

## 4. 数据流 & 所有权
1. **请求进入**：客户端调用 `POST /tasks` → FastAPI 生成 `task_id`，写入 `task:{id}`（状态 `PENDING`）。
2. **去重/缓存**：根据请求特征检查 `cache:{signature}`，命中则直接返回 `DONE` + 缓存结果。
3. **排队**：未命中缓存则将任务推送到 Redis Stream（字段仅包含引用 ID）。
4. **执行**：Worker `XREADGROUP`/`BLPOP` 拉取任务 → 标记 `RUNNING` → 执行模拟任务 → 写入结果并置 `DONE`。
5. **查询**：`GET /tasks/{id}` 查询 Hash；若任务完成且缓存存在，直接返回缓存并刷新 TTL。
6. **所有权**：任务状态仅由 Worker 修改；API 只能创建/读取，减少数据竞争。

## 5. 复杂度与特例控制
- **单一数据结构**：所有状态写入 Redis，不引入额外数据库，避免双写。
- **统一错误通道**：异常全部映射为 `TaskStatus=FAILED`，配合错误信息字段，API 层无需额外分支。
- **配置最少化**：仅暴露 Redis 连接串、任务并发度、缓存 TTL 三个核心配置；其余使用默认值。
- **扩展路径**：若需要 Kafka，可平滑替换队列实现，因为 `JobQueue` 接口提前抽象。

## 6. 关键风险与缓解
- **Redis 单点**：Compose 中提供最小部署，但在文档中强调生产应切换到有持久化/集群的 Redis 服务。
- **长任务阻塞**：Worker 基于 `asyncio`，提供 `MAX_CONCURRENCY` 配置；同时示范如何用多个 Worker 副本扩展。
- **Profiling 成本**：默认关闭，只在调试命令中开启，避免影响响应时间。
- **部署认知不足**：文档中附加 Nginx/Gunicorn 说明，确保面试可解释“线上拓扑”。

## 7. 面试应答模板
- **框架选择**：“FastAPI 基于 ASGI，天然适合高并发 IO；Pydantic 强制接口契约，自动生成 OpenAPI 方便协作。这套示例用它来暴露任务 API。”
- **Redis 价值**：“Redis 在项目里一肩挑缓存和队列，真实场景会用 Redis 缓存 + Kafka 队列，但示例展示了我如何权衡复杂度。”
- **异步任务**：“通过 Redis Stream 解耦 API 与 Worker，API 快速返回 task_id，Worker 后台执行，匹配 AI 推理这种长耗时任务。”
- **部署与性能**：“开发态用 `uvicorn`，生产态可以 `gunicorn -k uvicorn.workers.UvicornWorker -w 4 app.main:app`；Worker 数量随负载扩展，再配前置 Nginx/负载均衡。”
- **Profiling**：“有 `tools/profile.py` 的 cProfile 包装，可以在 Worker 里定位瓶颈函数，再决定是否重构或扩容。”

## 8. 后续路线
1. 按照《详细开发手册》实现 API、Worker、Redis 接入
2. 补充基本测试（提交→查询→完成）与性能压测脚本
3. 封装 Docker Compose，验证一条命令本地启动
4. 形成面试用 Demo 与讲稿

> 结论：该项目在保证最小复杂度的同时覆盖了面试中最常被问到的系统工程要素，是补齐短板的最高收益路径。
